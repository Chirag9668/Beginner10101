{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1972672,"sourceType":"datasetVersion","datasetId":1176843}],"dockerImageVersionId":30761,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-12T14:05:53.259950Z","iopub.execute_input":"2024-09-12T14:05:53.260471Z","iopub.status.idle":"2024-09-12T14:05:53.877247Z","shell.execute_reply.started":"2024-09-12T14:05:53.260419Z","shell.execute_reply":"2024-09-12T14:05:53.875907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\ndf = pd.read_csv('/kaggle/input/english-handwritten-characters-dataset/english.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-09-12T14:05:53.879058Z","iopub.execute_input":"2024-09-12T14:05:53.879440Z","iopub.status.idle":"2024-09-12T14:05:53.898014Z","shell.execute_reply.started":"2024-09-12T14:05:53.879402Z","shell.execute_reply":"2024-09-12T14:05:53.896190Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2024-09-12T14:05:53.899413Z","iopub.execute_input":"2024-09-12T14:05:53.899945Z","iopub.status.idle":"2024-09-12T14:05:53.912376Z","shell.execute_reply.started":"2024-09-12T14:05:53.899894Z","shell.execute_reply":"2024-09-12T14:05:53.910691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nimport numpy as np\nimport pandas as pd\n\n#Sample DataFrame creation for demonstration\ndf1 = pd.DataFrame({\n    'image': ['/kaggle/input/english-handwritten-characters-dataset/Img/img040-022.png'],\n    'label': [0]})\ndef load_image(image_path):\n    image = Image.open(image_path)\n    # Convert image to a numpy array and preprocess if needed (e.g., resizing)\n    image_array = np.array(image)\n    return image_array\n\n\nimages = []\nlabels = []\n\n# Iterate through the DataFrame to load images and labels\nfor index, row in df1.iterrows():\n    image_path = row['image']  # Replace 'image_column' with the actual column name for image paths\n    label = row['label']       # Replace 'label_column' with the actual column name for labels\n    \n    # Load and process the image\n    image_array = load_image(image_path)\n    \n    # Append to lists\n    images.append(image_array)\n    labels.append(label)\n\n# Convert lists to numpy arrays\nimages = np.array(images)\nlabels = np.array(labels)\n\nprint(f'Images shape: {images.shape}')\nprint(f'Labels shape: {labels.shape}')\n","metadata":{"execution":{"iopub.status.busy":"2024-09-12T14:05:53.915531Z","iopub.execute_input":"2024-09-12T14:05:53.916887Z","iopub.status.idle":"2024-09-12T14:05:53.953644Z","shell.execute_reply.started":"2024-09-12T14:05:53.916753Z","shell.execute_reply":"2024-09-12T14:05:53.952238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['label'].dtypes","metadata":{"execution":{"iopub.status.busy":"2024-09-12T14:05:53.955149Z","iopub.execute_input":"2024-09-12T14:05:53.955647Z","iopub.status.idle":"2024-09-12T14:05:53.963962Z","shell.execute_reply.started":"2024-09-12T14:05:53.955586Z","shell.execute_reply":"2024-09-12T14:05:53.962579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['label'] = df['label'].astype('category')\ndf['label'].dtypes","metadata":{"execution":{"iopub.status.busy":"2024-09-12T14:05:53.965445Z","iopub.execute_input":"2024-09-12T14:05:53.966166Z","iopub.status.idle":"2024-09-12T14:05:53.981484Z","shell.execute_reply.started":"2024-09-12T14:05:53.966121Z","shell.execute_reply":"2024-09-12T14:05:53.980274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df['image'].head())  # Display first few image paths","metadata":{"execution":{"iopub.status.busy":"2024-09-12T14:05:53.982804Z","iopub.execute_input":"2024-09-12T14:05:53.983278Z","iopub.status.idle":"2024-09-12T14:05:53.997105Z","shell.execute_reply.started":"2024-09-12T14:05:53.983239Z","shell.execute_reply":"2024-09-12T14:05:53.995874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import glob\nimport pandas as pd\nfrom PIL import Image\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\n\n# Load the DataFrame\n# Define image size\nimage_size = (64, 64)  # Example size, adjust as needed\n\n# Function to load and preprocess images\ndef load_image(image_path):\n    try:\n        image = Image.open(image_path)\n        image = image.resize(image_size)  # Resize image to target size\n        image_array = np.array(image) / 255.0  # Normalize pixel values\n        return image_array\n    except Exception as e:\n        print(f\"Error loading image {image_path}: {e}\")\n        return None\n\n# Get image file paths using glob\nimage_pattern = '/kaggle/input/english-handwritten-characters-dataset/Img/img*.png'  # Update pattern as needed\nimage_files = glob.glob(image_pattern)\n\n# Create a mapping from image filename to its path\nimage_path_mapping = {file.split('/')[-1]: file for file in image_files}\n\n# Convert DataFrame to lists\nimage_paths = []\nlabels = []\nfor idx, row in df.iterrows():\n    img_filename = row['image']  # Replace with your actual column name\n    if img_filename in image_path_mapping:\n        image_paths.append(image_path_mapping[img_filename])\n        labels.append(row['label'])  # Replace with your actual column name\n\n# Debug: Check number of paths and labels\nprint(f'Number of image paths: {len(image_paths)}')\nprint(f'Number of labels: {len(labels)}')\n\n# Load images and labels\nimages = []\nlabels_list = []\nfor img_path, lbl in zip(image_paths, labels):\n    img = load_image(img_path)\n    if img is not None:\n        images.append(img)\n        labels_list.append(lbl)\n\n# Convert lists to numpy arrays\nimages = np.array(images)\nlabels = np.array(labels_list)\n\n# Debug: Check shape of images and labels\nprint(f'Images shape: {images.shape}')\nprint(f'Labels shape: {labels.shape}')\n\n# Split into training and validation sets\nif images.shape[0] > 0:  # Ensure there's at least one sample\n    X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, random_state=42)\n    print(f'Number of training samples: {X_train.shape[0]}')\n    print(f'Number of validation samples: {X_val.shape[0]}')\nelse:\n    print('No images loaded. Please check your data and paths.')\n","metadata":{"execution":{"iopub.status.busy":"2024-09-12T14:05:53.998680Z","iopub.execute_input":"2024-09-12T14:05:53.999155Z","iopub.status.idle":"2024-09-12T14:05:54.220505Z","shell.execute_reply.started":"2024-09-12T14:05:53.999114Z","shell.execute_reply":"2024-09-12T14:05:54.219163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nimport matplotlib.pyplot as plt\n\n# Define the path to your image\nimage_path = '/kaggle/input/english-handwritten-characters-dataset/Img/img040-022.png'  # Update this path\n\n# Load the image\nimage = Image.open(image_path)\n\n# Display the image\nplt.imshow(image)\nplt.axis('off')  # Hide the axis\nplt.show()\nprint(df['image'].head())  # Print first few image paths\n","metadata":{"execution":{"iopub.status.busy":"2024-09-12T14:05:54.221837Z","iopub.execute_input":"2024-09-12T14:05:54.222223Z","iopub.status.idle":"2024-09-12T14:05:54.514751Z","shell.execute_reply.started":"2024-09-12T14:05:54.222183Z","shell.execute_reply":"2024-09-12T14:05:54.513382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom PIL import Image\nimport numpy as np\nimport os\nimport glob\nfrom sklearn.model_selection import train_test_split\n\n# Define image size\nimage_size = (64, 64)  # Example size, adjust as needed\n\n# Base directory for images\nbase_dir = '/kaggle/input/english-handwritten-characters-dataset/'\n\n# Function to load and preprocess images\ndef load_image(image_path):\n    try:\n        full_path = os.path.join(base_dir, image_path)  # Construct the full path\n        image = Image.open(full_path)\n        image = image.resize(image_size)  # Resize image to target size\n        image_array = np.array(image) / 255.0  # Normalize pixel values\n        return image_array\n    except Exception as e:\n        print(f\"Error loading image {full_path}: {e}\")\n        return None\n\n# Load the DataFrame (replace this with your actual DataFrame loading code)\n# df = pd.read_csv('/path/to/your/csvfile.csv')  # Ensure this path is correct\n\n# Convert DataFrame to lists\nimage_paths = df['image'].values\nlabels = df['label'].values\n\n# Load images and labels\nimages = []\nlabels_list = []\nfor img_path, lbl in zip(image_paths, labels):\n    img = load_image(img_path)\n    if img is not None:  # Only append if image loading was successful\n        images.append(img)\n        labels_list.append(lbl)\n\n# Convert lists to numpy arrays\nimages = np.array(images)\nlabels = np.array(labels_list)\n\n# Split into training and validation sets\nX_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, random_state=42)\n\nprint(f'Number of training samples: {X_train.shape[0]}')\nprint(f'Number of validation samples: {X_val.shape[0]}')\n","metadata":{"execution":{"iopub.status.busy":"2024-09-12T14:05:54.517889Z","iopub.execute_input":"2024-09-12T14:05:54.518265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n\n# Define the CNN model\nmodel = Sequential([\n    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n    MaxPooling2D((2, 2)),\n    Conv2D(64, (3, 3), activation='relu'),\n    MaxPooling2D((2, 2)),\n    Conv2D(128, (3, 3), activation='relu'),\n    MaxPooling2D((2, 2)),\n    Flatten(),\n    Dense(512, activation='relu'),\n    Dense(62, activation='softmax')  # 62 classes\n])\n\nmodel.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(np.unique(y_train))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.utils import to_categorical  # Import to_categorical\n\n# Initialize LabelEncoder\nlabel_encoder = LabelEncoder()\n\n# Fit label encoder and transform labels to integers\ny_train_encoded = label_encoder.fit_transform(y_train)\ny_val_encoded = label_encoder.transform(y_val)\n\n# Convert to categorical (one-hot encoding)\ny_train_categorical = to_categorical(y_train_encoded, num_classes=62)\ny_val_categorical = to_categorical(y_val_encoded, num_classes=62)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(np.unique(y_train_encoded))\nprint(np.unique(y_val_encoded))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the model\nhistory = model.fit(\n    X_train, y_train_categorical,\n    epochs=10,\n    batch_size=32,\n    validation_data=(X_val, y_val_categorical)\n)","metadata":{"execution":{"iopub.status.idle":"2024-09-12T14:09:13.184323Z","shell.execute_reply.started":"2024-09-12T14:07:32.854360Z","shell.execute_reply":"2024-09-12T14:09:13.182902Z"},"trusted":true},"execution_count":null,"outputs":[]}]}